{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import copy\n",
    "import random\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config={\n",
    "    \"batch_size\" : 256,\n",
    "    \"epochs\" : 500,\n",
    "    \"reg\" : 0.00005,\n",
    "    \"linearD\" : 512,\n",
    "    \"learning_rate\" : 0.0005,\n",
    "    \"model_path\" : './models/',\n",
    "    \"train_file\" : '/scratch/arjunth2001/t1.jsonl',\n",
    "    \"test_file\":'/scratch/arjunth2001/t2.jsonl',\n",
    "    \"features\" : ['sum_span_score', 'sum_doc_score', 'doc_sim', 'par_sim', 'min_doc_score', 'max_doc_score', 'avg_doc_score',\n",
    "                'max_span_score', 'min_span_score', 'avg_span_score', 'first_occurence', 'num_occurence', 'par_length'],\n",
    "    \"maximum_depth\" : 2,\n",
    "    \"maximum_depth_per_question\" : 2,\n",
    "    \"validation_set_split\" : 0.9,\n",
    "    \"early_stopping\" : 8,\n",
    "    \"cuda\":True,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_pairs(data):\n",
    "    training_pairs = []\n",
    "    new_pairs = 0\n",
    "    if len(data) - 1 < config[\"maximum_depth\"]:\n",
    "        limit = len(data) - 1\n",
    "    else:\n",
    "        limit = config[\"maximum_depth\"]\n",
    "    for i in range(limit):\n",
    "        #if data[i]['target'] == data[i + 1]['target']:\n",
    "            #continue\n",
    "        new_pairs += 1\n",
    "        x = (data[i], data[i + 1]\n",
    "                ) if data[i]['target'] == 1 else (data[i + 1], data[i])\n",
    "        training_pairs.append(x)\n",
    "        if new_pairs >= config[\"maximum_depth_per_question\"]:\n",
    "            break\n",
    "    return training_pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_subsample(features):\n",
    "    features = copy.deepcopy(features)\n",
    "    train, valid = [], []\n",
    "    with  open(config[\"train_file\"], 'r') as f:\n",
    "        for line in f:\n",
    "            answers = json.loads(line)\n",
    "            if len(answers) < 1:\n",
    "                continue\n",
    "            pairs = generate_pairs(answers)\n",
    "\n",
    "            if len(pairs) == 0:\n",
    "                continue\n",
    "\n",
    "            if random.random() < config[\"validation_set_split\"]:\n",
    "                train.extend(pairs)\n",
    "            else:\n",
    "                valid.extend(pairs)\n",
    "    return train, valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos  = [\"$\", \"''\", \",\",\"_SP\", \"-LRB-\", \"-RRB-\", \".\", \":\", \"ADD\", \"AFX\", \"CC\", \"CD\", \"DT\", \"EX\", \"FW\", \"HYPH\", \"IN\", \"JJ\", \"JJR\", \"JJS\", \"LS\", \"MD\", \"NFP\", \"NN\", \"NNP\", \"NNPS\", \"NNS\", \"PDT\", \"POS\", \"PRP\", \"PRP$\", \"RB\", \"RBR\", \"RBS\", \"RP\", \"SYM\", \"TO\", \"UH\", \"VB\", \"VBD\", \"VBG\", \"VBN\", \"VBP\", \"VBZ\", \"WDT\", \"WP\", \"WP$\", \"WRB\", \"XX\", \"``\"]\n",
    "ner = [\"CARDINAL\", \"DATE\", \"EVENT\", \"FAC\", \"GPE\", \"LANGUAGE\", \"LAW\", \"LOC\", \"MONEY\", \"NORP\", \"ORDINAL\", \"ORG\", \"PERCENT\", \"PERSON\", \"PRODUCT\", \"QUANTITY\", \"TIME\", \"WORK_OF_ART\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_pos_vec(data):\n",
    "    vec = np.zeros(len(pos))\n",
    "    #print(data[\"pos\"])\n",
    "    for i in eval(data[\"pos\"]):\n",
    "        vec[pos.index(i)] = 1\n",
    "    return vec\n",
    "\n",
    "def fill_ner_vec(data):\n",
    "    vec = np.zeros(len(ner))\n",
    "    for i in eval(data[\"ner\"]):\n",
    "        try:\n",
    "            vec[ner.index(i)] = 1\n",
    "        except:\n",
    "            pass\n",
    "    return vec\n",
    "\n",
    "def fill_ques_vec(data):\n",
    "    vec = np.zeros(13)\n",
    "    vec[data[\"question_type\"]]=1\n",
    "    return vec\n",
    "    \n",
    "def get_features(data):\n",
    "    pos = fill_pos_vec(data)\n",
    "    ner = fill_ner_vec(data)\n",
    "    ques = fill_ques_vec(data)\n",
    "    all_features = (ner, pos, ques)\n",
    "    return torch.from_numpy(np.concatenate(all_features, axis=-1)).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, valid_data  = generate_subsample([{\"name\":f } for f in config[\"features\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = []\n",
    "with open(config[\"test_file\"], 'r') as f:\n",
    "    for line in f:\n",
    "        test_data.append(json.loads(line))\n",
    "x, y, types, questions, answers = [], [], [], [], []\n",
    "for data in test_data:\n",
    "    tx, ty, ans, i = [], [], [], 0\n",
    "    for d in data:\n",
    "        ok = get_features(d)\n",
    "        types.append(d[\"question_type\"])\n",
    "        tx.append(ok)\n",
    "        ty.append(d['target'])\n",
    "        ans.append(d['para'])\n",
    "        if i == 0:\n",
    "            questions.append(d['q'])\n",
    "            i += 1\n",
    "    x.append(tx)\n",
    "    y.append(ty)\n",
    "    answers.append(ans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Evaluator(object):\n",
    "    def __init__(self,X, y, types, questions, answers):\n",
    "        self.X, self.y = X, y\n",
    "        self.n = len(self.y)\n",
    "        self.base, self.curr, self.top = 0, 0, 0\n",
    "        self.types = types\n",
    "        self.total_dist, self.wrong_dist = {}, {}\n",
    "        self.questions = questions\n",
    "        self.answers = answers\n",
    "\n",
    "    def initial_params(self):\n",
    "        X, y, questions, answers = [], [], [], []\n",
    "        with torch.no_grad():\n",
    "            for i, x in enumerate(self.X):\n",
    "                solvable = False\n",
    "                for j, _ in enumerate(x):\n",
    "                    if self.y[i][j] == 1:\n",
    "                        solvable = True\n",
    "                self.base += int(self.y[i][0])\n",
    "                if not solvable:\n",
    "                    continue\n",
    "                X.append(x)\n",
    "                questions.append(self.questions[i])\n",
    "                answers.append(self.answers[i])\n",
    "                y.append(self.y[i])\n",
    "                self.top += 1\n",
    "                if self.types[i] not in self.total_dist:\n",
    "                  self.total_dist[self.types[i]] = 0\n",
    "                  self.wrong_dist[self.types[i]] = 0\n",
    "                self.total_dist[self.types[i]] += 1\n",
    "        self.X, self.y = X, y\n",
    "        self.questions, self.answers = questions, answers\n",
    "        self.base = self.base / self.n\n",
    "        self.top = self.top / self.n\n",
    "\n",
    "    def evaluate(self, model):\n",
    "        wrong, correct = [], []\n",
    "        self.wrong_dist.clear()\n",
    "        with torch.no_grad():\n",
    "            for i, x in enumerate(self.X):\n",
    "                inputs = []\n",
    "                for j, candidate in enumerate(x):\n",
    "                    inputs.append(candidate)\n",
    "                scores = model.predict(torch.stack(inputs))\n",
    "                j = np.argmax(scores[0:10])\n",
    "                self.curr += int(self.y[i][j])        \n",
    "                if int(self.y[i][j]) == 0:\n",
    "                    if self.types[i] not in self.wrong_dist:\n",
    "                      self.wrong_dist[self.types[i]] = 0\n",
    "                    self.wrong_dist[self.types[i]] += 1\n",
    "                    wrong.append([i, j])\n",
    "                else:\n",
    "                  correct.append([i, j])\n",
    "\n",
    "        self.curr = self.curr / self.n\n",
    "        return correct, wrong"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator = Evaluator(x, y, types, questions, answers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PairwiseRankingDataSet():\n",
    "\n",
    "    def __init__(self, subsampled):\n",
    "        self.Xa, self.Xb, self.y = [], [], []\n",
    "        for xa, xb in subsampled:\n",
    "            if random.randint(1, 2) == 1:\n",
    "                self.Xa.append((get_features(xa)))\n",
    "                self.Xb.append((get_features(xb)))\n",
    "                self.y.append(torch.tensor(float(xa['target'])))\n",
    "            else:\n",
    "                self.Xa.append((get_features(xb)))\n",
    "                self.Xb.append((get_features(xa)))\n",
    "                self.y.append(torch.tensor(float(xb['target'])))\n",
    "        self.num_feat = len(self.Xa[0])\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.Xa[index], self.Xb[index], self.y[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = PairwiseRankingDataSet(train_data)\n",
    "valid_dataset = PairwiseRankingDataSet(valid_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batchify_pair(batch):\n",
    "    xa = torch.stack([ex[0] for ex in batch])\n",
    "    xb = torch.stack([ex[1] for ex in batch])\n",
    "    y = torch.stack([ex[2] for ex in batch])\n",
    "    return xa, xb, y\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=config[\"batch_size\"],\n",
    "    sampler=torch.utils.data.sampler.RandomSampler(train_dataset),\n",
    "    pin_memory=config[\"cuda\"],\n",
    "    collate_fn=batchify_pair\n",
    ")\n",
    "\n",
    "valid_loader = torch.utils.data.DataLoader(\n",
    "    valid_dataset,\n",
    "    batch_size=config[\"batch_size\"],\n",
    "    sampler=torch.utils.data.sampler.RandomSampler(valid_dataset),\n",
    "    pin_memory=config[\"cuda\"],\n",
    "    collate_fn=batchify_pair\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RankNetModel(nn.Module):\n",
    "\n",
    "    def __init__(self,  feat_size):\n",
    "        super(RankNetModel, self).__init__()\n",
    "\n",
    "        self.l1 = nn.Linear(feat_size, config[\"linearD\"])\n",
    "        self.act = nn.ReLU()\n",
    "        self.l2 = nn.Linear(config[\"linearD\"], 1)\n",
    "\n",
    "        self.output_sig = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, inputl, sig=False):\n",
    "        out = self.l1(inputl)\n",
    "        out = self.act(out)\n",
    "        out = self.l2(out)\n",
    "        if sig==True:\n",
    "            out =  self.output_sig(out)\n",
    "        return out\n",
    "\n",
    "    def forward_pairwise(self, input1, input2):\n",
    "        s1 = self.forward(input1)\n",
    "        s2 = self.forward(input2)\n",
    "        out = self.output_sig(s1 - s2)\n",
    "        return out\n",
    "\n",
    "    def predict(self, input):\n",
    "        return self.forward(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RankerNet(object):\n",
    "    def __init__(self, num_feat):\n",
    "        self.network = RankNetModel(num_feat)\n",
    "        self.optimizer = optim.Adam(self.network.parameters(), lr=config[\"learning_rate\"])\n",
    "        self.loss_func = nn.functional.mse_loss\n",
    "        self.loss_func_single = nn.functional.mse_loss\n",
    "\n",
    "    def predict(self, input):\n",
    "        self.network.eval()\n",
    "        input = Variable(input)\n",
    "        scores = self.network.predict(input)\n",
    "        return scores.data.cpu()\n",
    "\n",
    "    def eval_pairwise(self, input_l, input_r, targets):\n",
    "        self.network.eval()\n",
    "        with torch.no_grad():\n",
    "            targets = Variable(targets)\n",
    "            input_l = Variable(input_l)\n",
    "            input_r = Variable(input_r)\n",
    "\n",
    "            y_pred = self.network.forward_pairwise(input_l, input_r)\n",
    "\n",
    "            loss = self.loss_func_single(y_pred[:, 0], targets)\n",
    "        return loss.item()\n",
    "\n",
    "    def update_pairwise(self, input_l, input_r, targets):\n",
    "        self.network.train()\n",
    "\n",
    "        self.network.zero_grad()\n",
    "        targets = Variable(targets)\n",
    "        input_l = Variable(input_l)\n",
    "        input_r = Variable(input_r)\n",
    "\n",
    "        y_pred = self.network.forward_pairwise(input_l, input_r)\n",
    "\n",
    "        loss = self.loss_func_single(y_pred[:, 0], targets)\n",
    "        l2_reg = None\n",
    "        for W in self.network.parameters():\n",
    "            if l2_reg is None:\n",
    "                l2_reg = W.norm(2)\n",
    "            else:\n",
    "                l2_reg = l2_reg + W.norm(2)\n",
    "\n",
    "        loss = loss + config[\"reg\"] * l2_reg\n",
    "        loss.backward()\n",
    "        self.optimizer.step()\n",
    "        return loss.item()\n",
    "\n",
    "    def save(self, path):\n",
    "        torch.save(self.network, path)\n",
    "        pass\n",
    "\n",
    "    def load(self, path):\n",
    "        self.network = torch.load(path)\n",
    "        pass\n",
    "\n",
    "def calculate_loss(data_loader, model , typ):\n",
    "    loss = []\n",
    "    for data in data_loader:\n",
    "        inl, inr, target = data\n",
    "        l = model.eval_pairwise(inl, inr, target) if typ == \"val\" else model.update_pairwise(inl, inr, target)\n",
    "        loss.append(l)\n",
    "    return np.mean(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RankerNet(train_dataset.num_feat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_dataset.num_feat)\n",
    "model_save_path = config[\"model_path\"]+\"/model.pt\"\n",
    "best_val_loss = float('inf')\n",
    "best_val_iteration = 0\n",
    "\n",
    "for i in range(config[\"epochs\"]):\n",
    "    print('EPOCH '+str(i))\n",
    "    train_loss = calculate_loss(train_loader, model,'train')\n",
    "    val_loss = calculate_loss(valid_loader, model,'val')\n",
    "\n",
    "    print('Train loss '+ str(train_loss))\n",
    "    print('Validation loss '+str(val_loss))\n",
    "\n",
    "    if best_val_loss > val_loss:\n",
    "        print('Got a new best model, SAVING!!')\n",
    "        model.save(model_save_path)\n",
    "        best_val_loss = val_loss\n",
    "        best_val_iteration = 0\n",
    "\n",
    "    best_val_iteration += 1\n",
    "\n",
    "    if best_val_iteration > config[\"early_stopping\"]:\n",
    "        print(\"doing early stopping\")\n",
    "        break\n",
    "model.load(model_save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator.initial_params()\n",
    "correct, wrongs = evaluator.evaluate(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "18ad1a0b78abb685195a187077c0e4222d62dc0b12b6ffc1ffdc6633194f7113"
  },
  "kernelspec": {
   "display_name": "Python 3.7.11 64-bit ('py37': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
