{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "from tqdm.auto import tqdm\n",
    "import seaborn as sns\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "torch.manual_seed(69420)\n",
    "sns.set_style(\"darkgrid\")\n",
    "sns.set(rc={'figure.figsize':(11.7,8.27)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config={\n",
    "    \"batch_size\" : 256,\n",
    "    \"epochs\" : 100,\n",
    "    \"reg\" : 0.00005,\n",
    "    \"linearD\" : 512,\n",
    "    \"learning_rate\" : 0.0005,\n",
    "    \"model_path\" : './models/',\n",
    "    \"train_file\" : '/scratch/arjunth2001/t1.jsonl',\n",
    "    \"test_file\":'/scratch/arjunth2001/t2.jsonl',\n",
    "    \"features\" : ['sum_span_score', 'sum_doc_score', 'doc_sim', 'par_sim', 'min_doc_score', 'max_doc_score', 'avg_doc_score',\n",
    "                'max_span_score', 'min_span_score', 'avg_span_score', 'first_occurence', 'num_occurence', 'par_length'],\n",
    "    \"features2\" : ['sum_span_score', 'sum_doc_score',  'min_doc_score', 'max_doc_score', 'avg_doc_score',\n",
    "                'max_span_score', 'min_span_score', 'avg_span_score', 'first_occurence', 'num_occurence' ],\n",
    "    \"features3\" : [ 'doc_sim', 'par_sim', 'par_length'],\n",
    "    \"maximum_depth\" : 2,\n",
    "    \"maximum_pairs\" : 10,\n",
    "    \"validation_set_split\" : 0.9,\n",
    "    \"early_stopping\" : 20,\n",
    "    \"cuda\":True,\n",
    "    \"top_k\":4,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_pairs(data):\n",
    "    training_pairs = []\n",
    "    new_pairs = 0\n",
    "    for i in range(len(data)):\n",
    "        for j in range(i+1, len(data)):\n",
    "            if data[i]['target'] == data[j]['target']:\n",
    "                continue\n",
    "            new_pairs += 1\n",
    "            x = (data[i], data[j]) if data[i]['target'] == 1 else (data[j], data[i])\n",
    "            training_pairs.append(x)\n",
    "            if new_pairs == config[\"maximum_pairs\"]:\n",
    "                break\n",
    "        if new_pairs == config[\"maximum_pairs\"]:\n",
    "            break\n",
    "    return training_pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_subsample():\n",
    "    train, valid = [], []\n",
    "    with  open(config[\"train_file\"], 'r') as f:\n",
    "        for line in tqdm(f):\n",
    "            answers = json.loads(line)\n",
    "            if len(answers) < 1:\n",
    "                continue\n",
    "            pairs = generate_pairs(answers)\n",
    "\n",
    "            if len(pairs) == 0:\n",
    "                continue\n",
    "\n",
    "            if random.random() < config[\"validation_set_split\"]:\n",
    "                train.extend(pairs)\n",
    "            else:\n",
    "                valid.extend(pairs)\n",
    "    return train, valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos  = [\"$\", \"''\", \",\", \"_SP\", \"-LRB-\", \"-RRB-\", \".\", \":\", \"ADD\", \"AFX\", \"CC\", \"CD\", \"DT\", \"EX\", \"FW\", \"HYPH\", \"IN\", \"JJ\", \"JJR\", \"JJS\", \"LS\", \"MD\", \"NFP\", \"NN\", \"NNP\", \"NNPS\", \"NNS\", \"PDT\", \"POS\", \"PRP\", \"PRP$\", \"RB\", \"RBR\", \"RBS\", \"RP\", \"SYM\", \"TO\", \"UH\", \"VB\", \"VBD\", \"VBG\", \"VBN\", \"VBP\", \"VBZ\", \"WDT\", \"WP\", \"WP$\", \"WRB\", \"XX\", \"``\"]\n",
    "ner = [\"CARDINAL\", \"DATE\", \"EVENT\", \"FAC\", \"GPE\", \"LANGUAGE\", \"LAW\", \"LOC\", \"MONEY\", \"NORP\", \"ORDINAL\", \"ORG\", \"PERCENT\", \"PERSON\", \"PRODUCT\", \"QUANTITY\", \"TIME\", \"WORK_OF_ART\"]\n",
    "qtype = ['what was', 'what is', 'what', 'in what', 'in which', 'in','when', 'where', 'who', 'why', 'which', 'is', 'other']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_pos_vec(data):\n",
    "    vec = np.zeros(len(pos))\n",
    "    for i in eval(data[\"pos\"]):\n",
    "        vec[pos.index(i)] = 1\n",
    "    return vec\n",
    "\n",
    "def fill_ner_vec(data):\n",
    "    vec = np.zeros(len(ner))\n",
    "    for i in eval(data[\"ner\"]):\n",
    "        try:\n",
    "            vec[ner.index(i)] = 1\n",
    "        except:\n",
    "            pass\n",
    "    return vec\n",
    "\n",
    "def fill_ques_vec(data):\n",
    "    vec = np.zeros(len(qtype))\n",
    "    vec[data[\"question_type\"]]=1\n",
    "    return vec\n",
    "    \n",
    "def get_features(data):\n",
    "    pos = fill_pos_vec(data)\n",
    "    ner = fill_ner_vec(data)\n",
    "    ques = fill_ques_vec(data)\n",
    "    all_features = (ques)\n",
    "    all_features = (ner, pos, ques)\n",
    "    return torch.from_numpy(np.concatenate(all_features, axis=-1)).float()\n",
    "    #return torch.from_numpy(all_features).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, valid_data  = generate_subsample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Tester(object):\n",
    "    def __init__(self):\n",
    "        test_data = []\n",
    "        with open(config[\"test_file\"], 'r') as f:\n",
    "            for line in f:\n",
    "                test_data.append(json.loads(line))\n",
    "        self.X, self.y, self.types, self.questions, self.answers = [], [], [], [], []\n",
    "        for data in test_data:\n",
    "            tx, ty, ans, i = [], [], [], 0\n",
    "            for d in data:\n",
    "                ok = get_features(d)\n",
    "                self.types.append(d[\"question_type\"])\n",
    "                tx.append(ok)\n",
    "                ty.append(d['target'])\n",
    "                ans.append(d['para'])\n",
    "                if i == 0:\n",
    "                    self.questions.append(d['q'])\n",
    "                    i += 1\n",
    "            self.X.append(tx)\n",
    "            self.y.append(ty)\n",
    "            self.answers.append(ans)\n",
    "        self.curr_best = 0\n",
    "        self.baseline=0\n",
    "        self.n = len(self.y)\n",
    "        self.qtype= qtype\n",
    "        self.total_dist, self.wrong_dist = {k:0 for k in self.qtype}, {k:0 for k in self.qtype}\n",
    "        X, y, questions, answers = [], [], [], []\n",
    "        for i , x in enumerate(self.X):\n",
    "            solvable=False\n",
    "            for j,_ in enumerate(x):\n",
    "                if self.y[i][j]==1:\n",
    "                    solvable=True\n",
    "            self.baseline+=int(self.y[i][0])\n",
    "            if not solvable:\n",
    "                continue\n",
    "            self.total_dist[self.qtype[self.types[i]]] += 1\n",
    "            if int(self.y[i][0]) == 0:\n",
    "                self.wrong_dist[self.qtype[self.types[i]]] += 1\n",
    "            X, y, questions, answers = X + [x], y + [self.y[i]], questions + [self.questions[i]], answers + [self.answers[i]]\n",
    "        self.X, self.y, self.questions, self.answers = X, y, questions, answers\n",
    "        self.baseline=self.baseline/self.n\n",
    "\n",
    "    def test(self, model):\n",
    "        wrong, correct = 0 , 0\n",
    "        self.wrong_dist={k:0 for k in self.qtype}\n",
    "        with torch.no_grad():\n",
    "            model.eval()\n",
    "            for i, x in enumerate(self.X):\n",
    "                inp = []\n",
    "                for j, candidate in enumerate(x):\n",
    "                    inp.append(candidate)\n",
    "                inp = torch.stack(inp)\n",
    "                inp= Variable(inp)\n",
    "                scores = model.predict(inp).data.cpu()\n",
    "                j = np.argmax(scores[:config[\"top_k\"]])\n",
    "                self.curr_best += int(self.y[i][j])  \n",
    "                self.total_dist[self.qtype[self.types[i]]] += 1      \n",
    "                if int(self.y[i][j]) == 0:\n",
    "                    self.wrong_dist[self.qtype[self.types[i]]] += 1\n",
    "                    wrong+=1\n",
    "                else:\n",
    "                    correct+=1\n",
    "        self.curr_best = self.curr_best / self.n\n",
    "        return correct, wrong"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "def plot_losses(train_loss, validation_loss,epochs):\n",
    "    ax1 = sns.lineplot(x=[i for i in range(1, epochs+2)], y=train_loss, label = \"Train Loss\")\n",
    "    sns.lineplot(x=[i for i in range(1, epochs+2)], y=validation_loss, label = \"Val Loss\")\n",
    "    ax1.set(xlabel = \"Epochs\", ylabel = \"Loss\", title = \"Loss over epochs\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bar_plot(tester):\n",
    "    y = [1 - (tester.wrong_dist[i] / tester.total_dist[i]) if tester.total_dist[i]!=0 else 0 for  i in tester.qtype]\n",
    "    ax = sns.barplot(x=tester.qtype , y=y)\n",
    "    ax.set(xlabel = \"Question Type\", ylabel = \"Accuracies\", title = \"Accuracy for each question type\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tester = Tester()\n",
    "bar_plot(tester)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PairwiseRankingDataSet():\n",
    "\n",
    "    def __init__(self, subsampled):\n",
    "        self.Xa, self.Xb, self.y = [], [], []\n",
    "        for xa, xb in subsampled:\n",
    "            if random.randint(0, 1) == 0:\n",
    "                self.Xa.append((get_features(xa)))\n",
    "                self.Xb.append((get_features(xb)))\n",
    "                self.y.append(torch.tensor(float(xa['target'])))\n",
    "            else:\n",
    "                self.Xa.append((get_features(xb)))\n",
    "                self.Xb.append((get_features(xa)))\n",
    "                self.y.append(torch.tensor(float(xb['target'])))\n",
    "        self.num_feat = len(self.Xa[0])\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.Xa[index], self.Xb[index], self.y[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = PairwiseRankingDataSet(train_data)\n",
    "valid_dataset = PairwiseRankingDataSet(valid_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batchify_pair(batch):\n",
    "    xa = torch.stack([ex[0] for ex in batch])\n",
    "    xb = torch.stack([ex[1] for ex in batch])\n",
    "    y = torch.stack([ex[2] for ex in batch])\n",
    "    return xa, xb, y\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=config[\"batch_size\"],\n",
    "    sampler=torch.utils.data.sampler.RandomSampler(train_dataset),\n",
    "    pin_memory=config[\"cuda\"],\n",
    "    collate_fn=batchify_pair\n",
    ")\n",
    "\n",
    "valid_loader = torch.utils.data.DataLoader(\n",
    "    valid_dataset,\n",
    "    batch_size=config[\"batch_size\"],\n",
    "    sampler=torch.utils.data.sampler.RandomSampler(valid_dataset),\n",
    "    pin_memory=config[\"cuda\"],\n",
    "    collate_fn=batchify_pair\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RankQA(nn.Module):\n",
    "\n",
    "    def __init__(self,  feat_size):\n",
    "        super(RankQA, self).__init__()\n",
    "\n",
    "        self.l1 = nn.Linear(feat_size, config[\"linearD\"])\n",
    "        self.act = nn.ReLU()\n",
    "        self.l2 = nn.Linear(config[\"linearD\"], 1)\n",
    "\n",
    "        self.output_sig = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, inputl, sig=False):\n",
    "        out = self.l1(inputl)\n",
    "        out = self.act(out)\n",
    "        out = self.l2(out)\n",
    "        if sig==True:\n",
    "            out =  self.output_sig(out)\n",
    "        return out\n",
    "\n",
    "    def forward_pairwise(self, input1, input2):\n",
    "        s1 = self.forward(input1)\n",
    "        s2 = self.forward(input2)\n",
    "        out = self.output_sig(s1 - s2)\n",
    "        return out\n",
    "\n",
    "    def predict(self, input):\n",
    "        return self.forward(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(data_loader,model):\n",
    "    losses = []\n",
    "    model.train()\n",
    "    for data in data_loader:\n",
    "        inl, inr, target = data\n",
    "        model.zero_grad()\n",
    "        targets = Variable(target)\n",
    "        input_l = Variable(inl)\n",
    "        input_r = Variable(inr)\n",
    "        y_pred = model.forward_pairwise(input_l, input_r)\n",
    "        loss = loss_func(y_pred[:, 0], targets)\n",
    "        l2_reg = None\n",
    "        for W in model.parameters():\n",
    "            if l2_reg is None:\n",
    "                l2_reg = W.norm(2)\n",
    "            else:\n",
    "                l2_reg = l2_reg + W.norm(2)\n",
    "        loss = loss + config[\"reg\"] * l2_reg\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        losses.append(loss.item())\n",
    "        return np.mean(losses)\n",
    "def validate(data_loader, model):\n",
    "    losses = []\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for data in data_loader:\n",
    "            inl, inr, target = data\n",
    "            targets = Variable(target)\n",
    "            input_l = Variable(inl)\n",
    "            input_r = Variable(inr)\n",
    "            y_pred = model.forward_pairwise(input_l, input_r)\n",
    "            loss = loss_func(y_pred[:, 0], targets)\n",
    "            losses.append(loss.item())\n",
    "    return np.mean(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RankQA(train_dataset.num_feat)\n",
    "optimizer = optim.Adam(model.parameters(), lr=config[\"learning_rate\"])\n",
    "loss_func = nn.functional.mse_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_save_path = config[\"model_path\"]+\"/model.pt\"\n",
    "best_val_loss = np.inf\n",
    "best_val_iteration = 0\n",
    "tl , vl , acc = [], [],[]\n",
    "for i in range(config[\"epochs\"]):\n",
    "    print('EPOCH '+str(i))\n",
    "    train_loss = train(train_loader, model)\n",
    "    val_loss = validate(valid_loader, model)\n",
    "    vl.append(val_loss)\n",
    "    tl.append(train_loss)\n",
    "    print('Train loss '+ str(train_loss) + \",\"+'Validation loss '+str(val_loss))\n",
    "\n",
    "    if best_val_loss > val_loss:\n",
    "        print('Saving Best Model')\n",
    "        torch.save(model, model_save_path)\n",
    "        best_val_loss = val_loss\n",
    "        best_val_iteration = 0\n",
    "\n",
    "    best_val_iteration += 1\n",
    "    if best_val_iteration > config[\"early_stopping\"]:\n",
    "        print(\"Stopping Early..\")\n",
    "        break\n",
    "model= torch.load(model_save_path)\n",
    "plot_losses(tl,vl,i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct, wrongs = tester.test(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tester.baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tester.curr_best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct/(correct+wrongs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bar_plot(tester)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "18ad1a0b78abb685195a187077c0e4222d62dc0b12b6ffc1ffdc6633194f7113"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
