{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "39eb8500-649e-4365-932f-a2049928cd58",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Imports and Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9446d5f3-9cf6-4531-84f2-cedf85848e2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch import optim\n",
    "from tqdm.auto import tqdm\n",
    "from torch.autograd import Variable\n",
    "from torch.nn.functional import cross_entropy\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9692deea-cae5-46af-bfaa-d1801ceae388",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    \"epochs\": 10,\n",
    "    \"lr\": 1e-5,\n",
    "    \"num_feat\": 10,\n",
    "    \"lin_dim\": 10,\n",
    "    \"reg\": 0.1,\n",
    "    \"batch_size\": 32,\n",
    "    \"pairs_max_depth\": 10,\n",
    "    \"pairs_max_num\": 100,\n",
    "    \"features\" : ['sum_span_score', 'sum_doc_score', 'doc_score', 'span_score', 'min_doc_score', 'max_doc_score', 'avg_doc_score', 'max_span_score', 'min_span_score', 'avg_span_score', 'first_occ', 'num_occ', 'context_len', 'question_len'],\n",
    "    \"filenames\": [\"test1.txt\", \"test2.txt\"],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7333ad5b-3dfb-4041-8f5e-12be56de70a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device - cpu\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cpu')\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "print(\"device - \" + str(device))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e09e103-c3a7-492b-a411-9a4805a6115d",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "be939546-24de-43a8-8b07-930a4968a2b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Data():\n",
    "    def __init__(self):\n",
    "        self.x = 0\n",
    "    \n",
    "    def gen_rank_pairs(self, data, max_depth, max_num):\n",
    "        t = []\n",
    "        for i, d1 in enumerate(data):\n",
    "            i2 = min(i, max_depth)\n",
    "            for j, d2 in enumerate(data[:i2]):\n",
    "                if d1[\"target\"] - d2[\"target\"] == 1:\n",
    "                    t.append((d1, d2))\n",
    "                    max_num -= 1\n",
    "                if d2[\"target\"] - d1[\"target\"] == 1:\n",
    "                    t.append((d2, d1))\n",
    "                    max_num -= 1\n",
    "                if max_num == 0:\n",
    "                    break\n",
    "            if max_num == 0:\n",
    "                break\n",
    "        return t\n",
    "    \n",
    "    def gen_subsample(self, filenames):\n",
    "        train = []\n",
    "        val = []\n",
    "        for i, file in enumerate(filenames):\n",
    "            with open(file, \"r\") as f:\n",
    "                train.append([])\n",
    "                val.append([])\n",
    "                for line in f:\n",
    "                    ans = json.loads(line)\n",
    "                    if len(ans) == 0:\n",
    "                        continue\n",
    "                    pairs = gen_rank_pairs(ans, params[\"pairs_max_depth\"], params[\"pairs_max_num\"])\n",
    "                    if np.random.random() < params[\"val_split\"]:\n",
    "                        val[i].extend(pairs)\n",
    "                    else:\n",
    "                        train[i].extend(pairs)\n",
    "        return train, val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "76774904-6d7a-4428-9d4f-a51cb4ab9ad5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[({'target': 1, 'name': 'b'}, {'target': 0, 'name': 'a'}),\n",
       " ({'target': 1, 'name': 'b'}, {'target': 0, 'name': 'c'}),\n",
       " ({'target': 1, 'name': 'd'}, {'target': 0, 'name': 'a'}),\n",
       " ({'target': 1, 'name': 'b'}, {'target': 0, 'name': 'e'}),\n",
       " ({'target': 1, 'name': 'f'}, {'target': 0, 'name': 'a'}),\n",
       " ({'target': 1, 'name': 'b'}, {'target': 0, 'name': 'g'}),\n",
       " ({'target': 1, 'name': 'h'}, {'target': 0, 'name': 'a'}),\n",
       " ({'target': 1, 'name': 'b'}, {'target': 0, 'name': 'i'}),\n",
       " ({'target': 1, 'name': 'j'}, {'target': 0, 'name': 'a'})]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dummy_data = []\n",
    "\n",
    "for i in range(10):\n",
    "    dummy_data.append({\n",
    "        \"target\": i%2,\n",
    "        \"name\": chr(ord(\"a\")+i),\n",
    "    })\n",
    "\n",
    "gen_rank_pairs(dummy_data, 2, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7e297c75-95ce-4d3f-aeae-44e4521f870e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class rankqaDS(Dataset):\n",
    "    def __init__(self, sub_data):\n",
    "        self.x1 = []\n",
    "        self.x2 = []\n",
    "        self.y = []\n",
    "        for d1, d2 in sub_data:\n",
    "            if np.random.random() <= 0.5:\n",
    "                self.x1.append(Features.get_features(d1))\n",
    "                self.x2.append(Features.get_features(d2))\n",
    "                self.y.append(d1[\"target\"])\n",
    "            else:\n",
    "                self.x1.append(Features.get_features(d2))\n",
    "                self.x2.append(Features.get_features(d1))\n",
    "                self.y.append(d2[\"target\"])\n",
    "    \n",
    "    def __getitem__(self, indx):\n",
    "        return self.x1[indx], self.x2[indx], self.y[indx]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "368ea274-c372-426b-a24e-fe07f8084e6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_data = gen_subsample(params[\"filenames\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "939afb69-b354-42f0-be4f-e648d44a8bd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "f_data = rankqaDS(sub_data)\n",
    "data_loader = DataLoader(f_data, batch_size = params[\"batch_size\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6745034a-f305-44ca-ab65-6b39a79703d0",
   "metadata": {},
   "source": [
    "## Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09ba3391-de20-44b9-b061-7bb96c3c59c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Features():\n",
    "    def __init__(self, features):\n",
    "        self.features = features\n",
    "        self.pos_dict = {}\n",
    "        self.pos_values = ['NNP', 'JJ', 'NN', 'IN', ',', 'CC', 'DT', 'VBG', 'VB', 'NNS', 'POS', 'VBZ', 'RB', 'TO', 'FW', 'PRP$', 'CD', 'VBN', 'NNPS', 'JJR', 'VBP', ':', 'VBD', 'PRP', '#', 'JJS', '$', 'WRB', '-LRB-', '-RRB-', '.', '``', \"''\", 'PDT', 'MD', 'WP', 'RP', 'WDT', 'EX', 'UH', 'SYM', 'LS', 'RBS', 'RBR', 'WP$']\n",
    "        for indx, x in enumerate(self.pos_values):\n",
    "            self.pos_dict[x] = indx\n",
    "        self.ner_dict = {}\n",
    "        self.ner_values = ['location', 'person', 'organization', 'money', 'percent', 'date', 'time', 'o', 'set', 'duration', 'number', 'ordinal', 'misc']\n",
    "        for indx, x in enumerate(self.ner_values):\n",
    "            self.ner_dict[x] = indx\n",
    "        self.ques_dict = {}\n",
    "        self.ques_values = ['what was', 'what is', 'what', 'in what', 'in which', 'in', 'when', 'where', 'who', 'why', 'which', 'is', 'other']\n",
    "        for indx, x in enumerate(self.ques_values):\n",
    "            self.ques_dict[x] = indx\n",
    "\n",
    "    def fill_pos_vec(self, data):\n",
    "        vec = np.zeros(len(self.pos_values))\n",
    "        for i in data[\"span_pos\"]:\n",
    "            vec[self.pos_dict[i]] = 1\n",
    "        return vec\n",
    "\n",
    "    def fill_ner_vec(self, data):\n",
    "        vec = np.zeros(len(self.ner_values))\n",
    "        for i in data[\"span_pos\"]:\n",
    "            vec[self.pos_dict[i.lower()]] = 1\n",
    "        return vec\n",
    "\n",
    "    def fill_ques_vec(self, data):\n",
    "        vec = np.zeros(len(self.ques_values))\n",
    "        f_word = data[\"question\"].split()[0].lower()\n",
    "        if f_word in self.ques_values:\n",
    "            vec[self.ques_dict[f_word]] = 1\n",
    "        s_word = data[\"question\"].split()[1].lower()\n",
    "        fs_word = f_word + \" \" + s_word\n",
    "        if fs_word in self.ques_values:\n",
    "            vec[self.ques_dict[fs_word]] = 1\n",
    "        if f_word not in self.ques_values and fs_word not in self.ques_values:\n",
    "            vec[self.ques_dict[\"other\"]] = 1\n",
    "        return vec\n",
    "    \n",
    "    def get_features(self, data):\n",
    "        pos = self.fill_pos_vec(data)\n",
    "        ner = self.fill_ner_vec(data)\n",
    "        ques = self.fill_ques_vec(data)\n",
    "        return (pos, ner, ques, data[self.features])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e7734b2-3852-45e2-957f-7067df91d91b",
   "metadata": {},
   "source": [
    "## Evaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b97108ab-d939-4580-a290-03cdc53ab426",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Evaluator():\n",
    "    def __init__(self, x, y, k, model):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "        self.k = k\n",
    "    \n",
    "    def evaluate(self, model):\n",
    "        baseline = 0\n",
    "        current = 0\n",
    "        best = 0.\n",
    "        unsolvable = []\n",
    "        for i, x in enumerate(self.x):\n",
    "            sol = 0\n",
    "            xs = []\n",
    "            for j, ans in enumerate(x):\n",
    "                sol = int(sol or self.y[i][j])\n",
    "                xs.append(ans)\n",
    "            if not sol:\n",
    "                unsolvable.append(i)\n",
    "                continue\n",
    "            best += 1\n",
    "            baseline += int(self.y[i][0]) #Top answer before re-ranking\n",
    "            out = model.predict(xs)\n",
    "            best_indx = np.argmax(out[:self.k])\n",
    "            current += int(self.y[i][best_indx]) #Top answer after re-ranking\n",
    "            best_indx = np.argmax(out)\n",
    "            if int(self.y[i][best_indx]) == 0:\n",
    "                unsolvable.append(i)\n",
    "    \n",
    "        baseline_acc = baseline/best\n",
    "        current_acc = current/best\n",
    "        print(f\"Previous accuracy - {baseline_acc}%, Accuracy after re-ranking - {current_acc}%\")\n",
    "        return unsolvable"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bf3d385-e3d8-41b0-ac52-e02bc089d4af",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Re-ranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "beb115ce-2bbe-4984-8304-3f20693e0ba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReRanker(nn.Module):\n",
    "    def __init__(self, num_feat, lin_dim):\n",
    "        super(ReRanker, self).__init__()\n",
    "        self.l1 = nn.Linear(num_feat, lin_dim)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.l2 = nn.Linear(lin_dim, 1)\n",
    "        self.sig = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x1, x2):\n",
    "        out1 = self.forward_pass(x1)\n",
    "        out2 = self.forward_pass(x2)\n",
    "        out = self.sig(out1 - out2)\n",
    "        return out\n",
    "    \n",
    "    def forward_pass(self, x):\n",
    "        out = self.l1(x)\n",
    "        out = self.relu(out)\n",
    "        out = self.l2(out)\n",
    "        return out\n",
    "    \n",
    "    def predict(self, x):\n",
    "        out = self.forward_pass(x)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fc2cc1ce-68f6-40d3-b8ba-c282595018e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ReRanker(\n",
       "  (l1): Linear(in_features=10, out_features=10, bias=True)\n",
       "  (relu): ReLU()\n",
       "  (l2): Linear(in_features=10, out_features=1, bias=True)\n",
       "  (sig): Sigmoid()\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = ReRanker(params[\"num_feat\"], params[\"lin_dim\"])\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2c030e4a-4682-4e7f-8203-d69acf4dc428",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_func = nn.MSELoss()\n",
    "opt = optim.Adam(model.parameters(), lr=params[\"lr\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b12f172-17f0-4bed-a6ca-086e27fe9d3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(params[\"epochs\"]):\n",
    "    total_loss = 0\n",
    "    for batch in tqdm(data_loader):\n",
    "        x1, x2, target, i = batch\n",
    "        x1 = x1.to(device)\n",
    "        x2 = x2.to(device)\n",
    "        target = target.to(device)\n",
    "        y_pred = model.forward(x1, x2)\n",
    "        loss = loss_func(y_pred[:, 0], target)\n",
    "        reg_l2 = 0\n",
    "        for p in model.paramters():\n",
    "            reg_l2 += p.norm(2)\n",
    "        loss += params[\"reg\"] * reg_l2\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        opt.zero_grad()\n",
    "        total_loss += loss.detach().item()\n",
    "    \n",
    "    if epoch%2 == 1 or epoch == params[\"epochs\"] - 1:\n",
    "        torch.save({\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': opt.state_dict(),\n",
    "            'loss': total_loss,\n",
    "        }, f\"./checkpoints/model.pt\")\n",
    "    print(f\"Total Loss - {total_loss}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
