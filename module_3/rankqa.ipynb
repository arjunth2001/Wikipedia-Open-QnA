{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9446d5f3-9cf6-4531-84f2-cedf85848e2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch import optim\n",
    "from tqdm.auto import tqdm\n",
    "from torch.autograd import Variable\n",
    "from torch.nn.functional import cross_entropy\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9692deea-cae5-46af-bfaa-d1801ceae388",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    \"epochs\": 10,\n",
    "    \"lr\": 1e-5,\n",
    "    \"num_feat\": 10,\n",
    "    \"lin_dim\": 10,\n",
    "    \"reg\": 0.1,\n",
    "    \"batch_size\": 32,\n",
    "    \"pairs_max_depth\": 10,\n",
    "    \"pairs_max_num\": 100,\n",
    "    \"filenames\": [\"test1.txt\", \"test2.txt\"],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1b453e5d-b36e-4c00-b3b2-080b41179783",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_rank_pairs(data, max_depth, max_num):\n",
    "    t = []\n",
    "    for i, d1 in enumerate(data):\n",
    "        i2 = min(i, max_depth)\n",
    "        for j, d2 in enumerate(data[:i2]):\n",
    "            if d1[\"target\"] - d2[\"target\"] == 1:\n",
    "                t.append((d1, d2))\n",
    "                max_num -= 1\n",
    "            if d2[\"target\"] - d1[\"target\"] == 1:\n",
    "                t.append((d2, d1))\n",
    "                max_num -= 1\n",
    "            if max_num == 0:\n",
    "                break\n",
    "        if max_num == 0:\n",
    "            break\n",
    "    return t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "14928968-5691-4941-9d9c-147f86f87f30",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_subsample(filenames):\n",
    "    train = []\n",
    "    val = []\n",
    "    for i, file in enumerate(filenames):\n",
    "        with open(file, \"r\") as f:\n",
    "            train.append([])\n",
    "            val.append([])\n",
    "            for line in f:\n",
    "                ans = json.loads(line)\n",
    "                if len(ans) == 0:\n",
    "                    continue\n",
    "                pairs = gen_rank_pairs(ans, params[\"pairs_max_depth\"], params[\"pairs_max_num\"])\n",
    "                if np.random.random() < params[\"val_split\"]:\n",
    "                    val[i].extend(pairs)\n",
    "                else:\n",
    "                    train[i].extend(pairs)\n",
    "    return train, val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "76774904-6d7a-4428-9d4f-a51cb4ab9ad5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[({'target': 1, 'name': 'b'}, {'target': 0, 'name': 'a'}),\n",
       " ({'target': 1, 'name': 'b'}, {'target': 0, 'name': 'c'}),\n",
       " ({'target': 1, 'name': 'd'}, {'target': 0, 'name': 'a'}),\n",
       " ({'target': 1, 'name': 'b'}, {'target': 0, 'name': 'e'}),\n",
       " ({'target': 1, 'name': 'f'}, {'target': 0, 'name': 'a'}),\n",
       " ({'target': 1, 'name': 'b'}, {'target': 0, 'name': 'g'}),\n",
       " ({'target': 1, 'name': 'h'}, {'target': 0, 'name': 'a'}),\n",
       " ({'target': 1, 'name': 'b'}, {'target': 0, 'name': 'i'}),\n",
       " ({'target': 1, 'name': 'j'}, {'target': 0, 'name': 'a'})]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dummy_data = []\n",
    "\n",
    "for i in range(10):\n",
    "    dummy_data.append({\n",
    "        \"target\": i%2,\n",
    "        \"name\": chr(ord(\"a\")+i),\n",
    "    })\n",
    "\n",
    "gen_rank_pairs(dummy_data, 2, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7e297c75-95ce-4d3f-aeae-44e4521f870e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class rankqaDS(Dataset):\n",
    "    def __init__(self, sub_data):\n",
    "        self.x1 = []\n",
    "        self.x2 = []\n",
    "        self.y = []\n",
    "        for d1, d2 in sub_data:\n",
    "            if np.random.random() <= 0.5:\n",
    "                self.x1.append(d1)\n",
    "                self.x2.append(d2)\n",
    "                self.y.append(d1[\"target\"])\n",
    "            else:\n",
    "                self.x1.append(d2)\n",
    "                self.x2.append(d1)\n",
    "                self.y.append(d2[\"target\"])\n",
    "    \n",
    "    def __getitem__(self, indx):\n",
    "        return self.x1[indx], self.x2[indx], self.y[indx]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "368ea274-c372-426b-a24e-fe07f8084e6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_data = gen_subsample(params[\"filenames\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "939afb69-b354-42f0-be4f-e648d44a8bd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "f_data = rankqaDS(sub_data)\n",
    "data_loader = DataLoader(f_data, batch_size = params[\"batch_size\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7333ad5b-3dfb-4041-8f5e-12be56de70a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device - cpu\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cpu')\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "print(\"device - \" + str(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "beb115ce-2bbe-4984-8304-3f20693e0ba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReRanker(nn.Module):\n",
    "    def __init__(self, num_feat, lin_dim):\n",
    "        super(ReRanker, self).__init__()\n",
    "        self.l1 = nn.Linear(num_feat, lin_dim)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.l2 = nn.Linear(lin_dim, 1)\n",
    "        self.sig = nn.Sigmoid()\n",
    "\n",
    "    def forward(x1, x2):\n",
    "        out1 = self.l1(x1)\n",
    "        out1 = self.relu(out1)\n",
    "        out1 = self.l2(out1)\n",
    "        out2 = self.l1(x2)\n",
    "        out2 = self.relu(out2)\n",
    "        out2 = self.l2(out2)\n",
    "        out = self.sig(out1 - out2)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fc2cc1ce-68f6-40d3-b8ba-c282595018e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ReRanker(\n",
       "  (l1): Linear(in_features=10, out_features=10, bias=True)\n",
       "  (relu): ReLU()\n",
       "  (l2): Linear(in_features=10, out_features=1, bias=True)\n",
       "  (sig): Sigmoid()\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = ReRanker(params[\"num_feat\"], params[\"lin_dim\"])\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2c030e4a-4682-4e7f-8203-d69acf4dc428",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_func = nn.MSELoss()\n",
    "opt = optim.Adam(model.parameters(), lr=params[\"lr\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b12f172-17f0-4bed-a6ca-086e27fe9d3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(params[\"epochs\"]):\n",
    "    total_loss = 0\n",
    "    for batch in tqdm(data_loader):\n",
    "        x1, x2, target, i = batch\n",
    "        x1 = x1.to(device)\n",
    "        x2 = x2.to(device)\n",
    "        target = target.to(device)\n",
    "        y_pred = model.forward(x1, x2)\n",
    "        loss = loss_func(y_pred[:, 0], target)\n",
    "        reg_l2 = 0\n",
    "        for p in model.paramters():\n",
    "            reg_l2 += p.norm(2)\n",
    "        loss += params[\"reg\"] * reg_l2\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        opt.zero_grad()\n",
    "        total_loss += loss.detach().item()\n",
    "    \n",
    "    if epoch%2 == 1 or epoch == params[\"epochs\"] - 1:\n",
    "        torch.save({\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': opt.state_dict(),\n",
    "            'loss': total_loss,\n",
    "        }, f\"./checkpoints/model.pt\")\n",
    "    print(f\"Total Loss - {total_loss}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
