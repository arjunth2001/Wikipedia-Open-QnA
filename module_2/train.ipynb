{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5075a91-569d-4bd0-a352-f16f0ddfb2e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torchtext\n",
    "import torch\n",
    "from torch import nn\n",
    "import json, re, unicodedata, string, typing, time\n",
    "import torch.nn.functional as F\n",
    "import spacy\n",
    "from collections import Counter\n",
    "from tqdm.auto import tqdm\n",
    "import pickle\n",
    "from nltk import word_tokenize\n",
    "import ipynb.fs\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "from .defs.model import *\n",
    "load = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a1713ed-ccf1-43e0-b053-0f981ee48fbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "print('device: ' + str(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03e32837-147f-4a78-9b8d-d86983e474d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SquadDataset:    \n",
    "    def __init__(self, data, batch_size):\n",
    "        self.batch_size = batch_size\n",
    "        data = [data[i:i+self.batch_size] for i in range(0, len(data), self.batch_size)]\n",
    "        self.data = data\n",
    "    def get_span(self, text):\n",
    "        text = nlp(text, disable=['parser','tagger','ner'])\n",
    "        span = [(w.idx, w.idx+len(w.text)) for w in text]\n",
    "        return span\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __iter__(self):\n",
    "        for batch in self.data:                \n",
    "            spans = []\n",
    "            context_text = []\n",
    "            answer_text = []\n",
    "            \n",
    "            max_context_len = max([len(ctx[0]) for ctx in batch.context_ids])\n",
    "            padded_context = torch.LongTensor(len(batch), max_context_len).fill_(1)\n",
    "            context_fts = torch.LongTensor(len(batch),max_context_len,2).fill_(0)\n",
    "            for ctx in batch.context:\n",
    "                context_text.append(ctx)\n",
    "                spans.append(self.get_span(ctx))\n",
    "            \n",
    "            for ans in batch.answer:\n",
    "                answer_text.append(ans)\n",
    "                \n",
    "            for i, ctx in enumerate(batch.context_ids):\n",
    "                padded_context[i, :len(ctx[0])] = torch.LongTensor(ctx[0])\n",
    "                context_fts[i,:len(ctx[1])] = torch.LongTensor(ctx[1])\n",
    "            \n",
    "            max_question_len = max([len(ques[0]) for ques in batch.question_ids])\n",
    "            padded_question = torch.LongTensor(len(batch), max_question_len).fill_(1)\n",
    "            \n",
    "            for i, ques in enumerate(batch.question_ids):\n",
    "                padded_question[i,: len(ques[0])] = torch.LongTensor(ques[0])\n",
    "                \n",
    "            \n",
    "            label = torch.LongTensor(list(batch.label_idx))\n",
    "            context_mask = torch.eq(padded_context, 1)\n",
    "            question_mask = torch.eq(padded_question, 1)\n",
    "            \n",
    "            ids = list(batch.id)  \n",
    "            \n",
    "            yield (padded_context, padded_question, context_mask, \n",
    "                   question_mask, label, context_text, answer_text, ids, context_fts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f16b23f2-cf80-4018-a184-f583cdfe90bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_pickle('/scratch/arjunth2001/drqa/drqatrain.pkl')#.head(500)\n",
    "valid_df = pd.read_pickle('/scratch/arjunth2001/drqa/drqavalid.pkl')#.head(500)\n",
    "train_dataset = SquadDataset(train_df, 32)\n",
    "valid_dataset = SquadDataset(valid_df, 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c63ec93-d490-4580-9be1-acfbce3965a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "HIDDEN_DIM = 128\n",
    "EMB_DIM = 300\n",
    "NUM_LAYERS = 3\n",
    "NUM_DIRECTIONS = 2\n",
    "DROPOUT = 0.3\n",
    "LR = 1e-5\n",
    "model = DocumentReader(HIDDEN_DIM,\n",
    "                       EMB_DIM, \n",
    "                       NUM_LAYERS, \n",
    "                       NUM_DIRECTIONS, \n",
    "                       DROPOUT, \n",
    "                       device).to(device)\n",
    "optimizer = torch.optim.Adamax(model.parameters(),lr=LR)\n",
    "model_path=\"models/model.pt\"\n",
    "if load :\n",
    "    loaded_state_dict = torch.load(model_path,  map_location=device)\n",
    "    model.load_state_dict(loaded_state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f87e310-3922-43a8-97a8-adf8591f8244",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_dataset):    \n",
    "    train_loss = 0.\n",
    "    model.train()\n",
    "    for batch in tqdm(train_dataset):\n",
    "        context, question, context_mask, question_mask, label, ctx, ans, ids , fts = batch\n",
    "        context, context_mask, question, question_mask, label, fts = context.to(device), context_mask.to(device),\\\n",
    "                                    question.to(device), question_mask.to(device), label.to(device), fts.to(device)\n",
    "        \n",
    "        start_pred, end_pred = model(context, question, context_mask, question_mask,fts)\n",
    "        start_label, end_label = label[:,0], label[:,1]\n",
    "        \n",
    "        loss = F.cross_entropy(start_pred, start_label) + F.cross_entropy(end_pred, end_label)\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 10)\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        train_loss += loss.item()\n",
    "    return train_loss/len(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "091225ed-d7dc-4cf0-b31e-b7de3b59b61f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def valid(model, valid_dataset):\n",
    "    valid_loss = 0.\n",
    "    f1, em = 0., 0.\n",
    "    model.eval()\n",
    "    predictions = {}\n",
    "    for batch in tqdm(valid_dataset):\n",
    "        context, question, context_mask, question_mask, label, context_text, answers, ids, fts = batch\n",
    "        context, context_mask, question, question_mask, label, fts = context.to(device), context_mask.to(device),\\\n",
    "                                    question.to(device), question_mask.to(device), label.to(device), fts.to(device)\n",
    "        with torch.no_grad():\n",
    "            p1, p2 = model(context, question, context_mask, question_mask, fts)\n",
    "            y1, y2 = label[:,0], label[:,1]\n",
    "            loss = F.cross_entropy(p1, y1) + F.cross_entropy(p2, y2)\n",
    "            valid_loss += loss.item()\n",
    "            batch_size, c_len = p1.size()\n",
    "            ls = nn.LogSoftmax(dim=1)\n",
    "            mask = (torch.ones(c_len, c_len) * float('-inf')).to(device).tril(-1).unsqueeze(0).expand(batch_size, -1, -1)\n",
    "            score = (ls(p1).unsqueeze(2) + ls(p2).unsqueeze(1)) + mask\n",
    "            score, s_idx = score.max(dim=1)\n",
    "            score, e_idx = score.max(dim=1)\n",
    "            s_idx = torch.gather(s_idx, 1, e_idx.view(-1, 1)).squeeze()\n",
    "            for i in range(batch_size):\n",
    "                id = ids[i]\n",
    "                pred = context[i][s_idx[i]:e_idx[i]+1]\n",
    "                pred = ' '.join([idx2word[idx.item()] for idx in pred])\n",
    "                predictions[id] = pred     \n",
    "    em, f1 = evaluate(predictions)            \n",
    "    return valid_loss/len(valid_dataset), em, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00ddad1f-0531-40bd-ad94-160cef09ca60",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(predictions):\n",
    "    with open('../data/dev-v2.0.json','r',encoding='utf-8') as f:\n",
    "        dataset = json.load(f)\n",
    "        \n",
    "    dataset = dataset['data']\n",
    "    f1 = exact_match = total = 0\n",
    "    for article in dataset:\n",
    "        for paragraph in article['paragraphs']:\n",
    "            for qa in paragraph['qas']:\n",
    "                total += 1\n",
    "                if qa['id'] not in predictions:\n",
    "                    continue\n",
    "                \n",
    "                ground_truths = list(map(lambda x: x['text'], qa['answers']))\n",
    "                \n",
    "                prediction = predictions[qa['id']]\n",
    "                \n",
    "                exact_match += metric_max_over_ground_truths(\n",
    "                    exact_match_score, prediction, ground_truths)\n",
    "                \n",
    "                f1 += metric_max_over_ground_truths(\n",
    "                    f1_score, prediction, ground_truths)\n",
    "                \n",
    "    \n",
    "    exact_match = 100.0 * exact_match / total\n",
    "    f1 = 100.0 * f1 / total\n",
    "    \n",
    "    return exact_match, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b50254f-1451-4bd5-a273-28a2f2704907",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_answer(s):\n",
    "    def remove_articles(text):\n",
    "        return re.sub(r'\\b(a|an|the)\\b', ' ', text)\n",
    "\n",
    "    def white_space_fix(text):\n",
    "        return ' '.join(text.split())\n",
    "\n",
    "    def remove_punc(text):\n",
    "        exclude = set(string.punctuation)\n",
    "        return ''.join(ch for ch in text if ch not in exclude)\n",
    "\n",
    "    def lower(text):\n",
    "        return text.lower()\n",
    "\n",
    "    return white_space_fix(remove_articles(remove_punc(lower(s))))\n",
    "\n",
    "\n",
    "def metric_max_over_ground_truths(metric_fn, prediction, ground_truths):\n",
    "    scores_for_ground_truths = []\n",
    "    for ground_truth in ground_truths:\n",
    "        score = metric_fn(prediction, ground_truth)\n",
    "        scores_for_ground_truths.append(score)\n",
    "        \n",
    "    return max(scores_for_ground_truths)\n",
    "\n",
    "\n",
    "def f1_score(prediction, ground_truth):\n",
    "    prediction_tokens = normalize_answer(prediction).split()\n",
    "    ground_truth_tokens = normalize_answer(ground_truth).split()\n",
    "    common = Counter(prediction_tokens) & Counter(ground_truth_tokens)\n",
    "    num_same = sum(common.values())\n",
    "    if num_same == 0:\n",
    "        return 0\n",
    "    precision = 1.0 * num_same / len(prediction_tokens)\n",
    "    recall = 1.0 * num_same / len(ground_truth_tokens)\n",
    "    f1 = (2 * precision * recall) / (precision + recall)\n",
    "    return f1\n",
    "\n",
    "\n",
    "def exact_match_score(prediction, ground_truth):\n",
    "    return (normalize_answer(prediction) == normalize_answer(ground_truth))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "976913e4-53c7-4ef0-bffe-27f9db7c60b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('/scratch/arjunth2001/drqa/drqastoi.pickle','rb') as handle:\n",
    "    word2idx = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4f1eb3d-abdc-4552-a4b8-48e435cbc3b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx2word = {v : k for k,v in word2idx.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f6d4256-d831-493b-b153-cafa5d09c1ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_losses = []\n",
    "valid_losses = []\n",
    "ems = []\n",
    "f1s = []\n",
    "epochs = 50\n",
    "best_loss = np.inf\n",
    "best_loss = np.inf\n",
    "best_epoch = 0\n",
    "for epoch in range(epochs):\n",
    "    print(f\"Epoch {epoch+1}\") \n",
    "    train_loss = train(model, train_dataset)\n",
    "    valid_loss, em, f1 = valid(model, valid_dataset)\n",
    "    train_losses.append(train_loss)\n",
    "    valid_losses.append(valid_loss)\n",
    "    ems.append(em)\n",
    "    f1s.append(f1)\n",
    "    if (valid_loss < best_loss):\n",
    "        torch.save(model.state_dict(), model_path)\n",
    "        best_loss = valid_loss\n",
    "        best_epoch = epoch+1\n",
    "    print(\"====================================================================================\")\n",
    "    print(f\"Epoch train loss : {train_loss}  valid loss: {valid_loss} EM: {em} F1: {f1} Best Epoch: {best_epoch}\")\n",
    "    print(\"====================================================================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd764a40-02c5-49b7-940f-25004746512a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
