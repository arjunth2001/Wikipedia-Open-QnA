{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aff4e8f7-5afe-4c51-97c7-daddfc50dbdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipynb.fs\n",
    "import pandas as pd\n",
    "import spacy\n",
    "from collections import Counter\n",
    "from tqdm.auto import tqdm\n",
    "from .defs.utils import *\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65a4fafa-8e71-4dbf-8ca6-5a0fbd85568e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = load_json('../data/train-v2.0.json')\n",
    "valid_data = load_json('../data/dev-v2.0.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a00b2a6-140b-461c-9480-1fda267aaf8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.DataFrame(parse_data(train_data))#.head(500)\n",
    "valid_df = pd.DataFrame(parse_data(valid_data))#.head(500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13a84437-4984-4ce7-b6fd-8492e93813a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.context = train_df.context.apply(normalize_spaces)\n",
    "valid_df.context = valid_df.context.apply(normalize_spaces)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb93f89c-1e11-4f29-b829-d5902b170ff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_text = []\n",
    "for df in [train_df,valid_df]:\n",
    "    unique_contexts = list(df.context.unique())\n",
    "    unique_questions = list(df.question.unique())\n",
    "    vocab_text.extend(unique_contexts + unique_questions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "146300b5-7e86-4c8d-ae31-0c547e5a809b",
   "metadata": {},
   "outputs": [],
   "source": [
    "words = []\n",
    "for sent in tqdm(vocab_text):\n",
    "    for word in nlp(sent, disable=['parser','tagger','ner']):\n",
    "        words.append(word.text)\n",
    "word_counter = Counter(words)\n",
    "word_vocab = sorted(word_counter, key=word_counter.get, reverse=True)\n",
    "print(f\"raw-vocab: {len(word_vocab)}\")\n",
    "word_vocab.insert(0, '<unk>')\n",
    "word_vocab.insert(1, '<pad>')\n",
    "print(f\"vocab-length: {len(word_vocab)}\")\n",
    "word2idx = {word:idx for idx, word in enumerate(word_vocab)}\n",
    "print(f\"word2idx-length: {len(word2idx)}\")\n",
    "idx2word = {v:k for k,v in word2idx.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9c68947-b7b5-44aa-a0e9-d1d6890a4a96",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('/scratch/arjunth2001/drqa/drqastoi.pickle','wb') as handle:\n",
    "    pickle.dump(word2idx, handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d5c37d6-293d-40a5-92b0-e96d4e3126db",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('/scratch/arjunth2001/drqa/drqastoi.pickle','rb') as handle:\n",
    "    word2idx = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5effc2be-61f5-45be-b1ad-041ca03ce080",
   "metadata": {},
   "outputs": [],
   "source": [
    "%time train_df['context_ids'] = train_df.context.progress_apply(text_to_ids, word2idx=word2idx, nlp=nlp)\n",
    "%time valid_df['context_ids'] = valid_df.context.progress_apply(text_to_ids, word2idx=word2idx, nlp=nlp)\n",
    "\n",
    "%time train_df['question_ids'] = train_df.question.progress_apply(text_to_ids,  word2idx=word2idx, nlp=nlp)\n",
    "%time valid_df['question_ids'] = valid_df.question.progress_apply(text_to_ids,  word2idx=word2idx, nlp=nlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78e7e98e-a07c-4c7e-8692-4fad8e907534",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_err = get_error_indices(train_df, idx2word , nlp)\n",
    "valid_err = get_error_indices(valid_df, idx2word, nlp)\n",
    "train_df.drop(train_err, inplace=True)\n",
    "valid_df.drop(valid_err, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05f54110-d750-4442-bf3d-4640e75f857d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_label_idx = train_df.progress_apply(index_answer, axis=1, idx2word=idx2word, nlp= nlp)\n",
    "valid_label_idx = valid_df.progress_apply(index_answer, axis=1, idx2word=idx2word,nlp = nlp)\n",
    "train_df['label_idx'] = train_label_idx\n",
    "valid_df['label_idx'] = valid_label_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef4ff7c0-3dbb-4ef3-93d4-ba8bc0fda07e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('/scratch/arjunth2001/drqa/drqastoi.pickle','wb') as handle:\n",
    "    pickle.dump(word2idx, handle)\n",
    "    \n",
    "train_df.to_pickle('/scratch/arjunth2001/drqa/drqatrain.pkl')\n",
    "valid_df.to_pickle('/scratch/arjunth2001/drqa/drqavalid.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1122864c-ef0e-45f8-bc2c-0ea8e852c4b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "glove_dict = {}\n",
    "with open(\"/scratch/arjunth2001/glove.840B.300d.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    for line in tqdm(f):\n",
    "        values = line.split(' ')\n",
    "        word = values[0]\n",
    "        vector = np.asarray(values[1:], dtype=\"float32\")\n",
    "        glove_dict[word] = vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c2dc2c8-63bf-4052-8d8c-847a6d6f1a4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights_matrix = np.zeros((len(word_vocab), 300))\n",
    "for i, word in enumerate(word_vocab):\n",
    "    try:\n",
    "        weights_matrix[i] = glove_dict[word]\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03e02eb6-a402-46d5-8471-545577a423d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('/scratch/arjunth2001/drqa/drqaglove_vt.npy',weights_matrix)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
